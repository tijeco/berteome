berteome
================

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

## Install

`pip install berteome`

# Getting started

Berteome makes use of the masked language model of BERT to determine
predictions for all residues in a protein sequence.

The main `berteome` library can be imported as follows:

``` python
from berteome import berteome
```

The `modelLoader` class can be used to show what models are supported by
`berteome`.

``` python
berteome_models = berteome.modelLoader()
berteome_models.supported_models
```

    ['Rostlab/prot_bert',
     'facebook/esm2_t33_650M_UR50D',
     'facebook/esm1b_t33_650M_UR50S']

All of these models are distributed through huggingface, and berteome
makes great use of it’s API.

## Load model

To load prot_bert model, run the following:

``` python
bert_tokenizer, bert_model = berteome_models.load_model("Rostlab/prot_bert")
```

    Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']
    - This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
    - This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).

The language models utilized by `berteome` were trained using a masked
token approach. In this approach, a random amino acid is masked in a
protein and the model is trained to predict what the amino acid should
be. These models do this on an incredibly large amount of protein
sequences, to the point that they begin to learn the language of protein
sequence space as we currently know it. For instance, it can start to
learn, which residues are unlikely to exist at a given point in a
protein. Using these models, you can place a mask at any given residue
in the protein, and the model will generate a probability score for all
the possible amino acids that could go there.

`berteome` allows the user to take the models and begin to really
investigate these predictions for a given protein sequence, by masking
every single residue in the protein sequence and predicting the
probabilities for all the possible amino acids. The result is a nice,
easy to work with pandas data frame. To make this dataframe for a very
simple peptide sequence (`MENDEL`), do the following:

``` python
mendel_berteome = berteome.modelPredDF("MENDEL",bert_tokenizer, bert_model)
mendel_berteome.df
```

  <div id="df-fc9f64ed-b8b8-433f-bc51-a92954702041">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>wt</th>
      <th>wtIndex</th>
      <th>wtScore</th>
      <th>n_effective</th>
      <th>topAA</th>
      <th>topAAscore</th>
      <th>A</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
      <th>...</th>
      <th>M</th>
      <th>N</th>
      <th>P</th>
      <th>Q</th>
      <th>R</th>
      <th>S</th>
      <th>T</th>
      <th>V</th>
      <th>W</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>M</td>
      <td>1</td>
      <td>0.076601</td>
      <td>16.680502</td>
      <td>E</td>
      <td>0.118907</td>
      <td>0.036697</td>
      <td>0.011504</td>
      <td>0.048245</td>
      <td>0.118907</td>
      <td>...</td>
      <td>0.076601</td>
      <td>0.072661</td>
      <td>0.024722</td>
      <td>0.038672</td>
      <td>0.043104</td>
      <td>0.070280</td>
      <td>0.056544</td>
      <td>0.049927</td>
      <td>0.007781</td>
      <td>0.021699</td>
    </tr>
    <tr>
      <th>1</th>
      <td>E</td>
      <td>2</td>
      <td>0.074830</td>
      <td>17.599150</td>
      <td>L</td>
      <td>0.106501</td>
      <td>0.045721</td>
      <td>0.015662</td>
      <td>0.041921</td>
      <td>0.074830</td>
      <td>...</td>
      <td>0.043581</td>
      <td>0.062667</td>
      <td>0.025277</td>
      <td>0.036911</td>
      <td>0.055543</td>
      <td>0.064424</td>
      <td>0.049955</td>
      <td>0.056789</td>
      <td>0.012691</td>
      <td>0.029893</td>
    </tr>
    <tr>
      <th>2</th>
      <td>N</td>
      <td>3</td>
      <td>0.041990</td>
      <td>14.518506</td>
      <td>E</td>
      <td>0.184365</td>
      <td>0.043564</td>
      <td>0.009685</td>
      <td>0.162591</td>
      <td>0.184365</td>
      <td>...</td>
      <td>0.041484</td>
      <td>0.041990</td>
      <td>0.019992</td>
      <td>0.025515</td>
      <td>0.029433</td>
      <td>0.048105</td>
      <td>0.030303</td>
      <td>0.054742</td>
      <td>0.007430</td>
      <td>0.024924</td>
    </tr>
    <tr>
      <th>3</th>
      <td>D</td>
      <td>4</td>
      <td>0.049748</td>
      <td>17.561045</td>
      <td>L</td>
      <td>0.109087</td>
      <td>0.042082</td>
      <td>0.013244</td>
      <td>0.049748</td>
      <td>0.086194</td>
      <td>...</td>
      <td>0.040080</td>
      <td>0.060822</td>
      <td>0.032024</td>
      <td>0.039689</td>
      <td>0.046228</td>
      <td>0.062323</td>
      <td>0.044901</td>
      <td>0.058937</td>
      <td>0.010875</td>
      <td>0.026596</td>
    </tr>
    <tr>
      <th>4</th>
      <td>E</td>
      <td>5</td>
      <td>0.086915</td>
      <td>17.921403</td>
      <td>L</td>
      <td>0.090806</td>
      <td>0.046641</td>
      <td>0.018770</td>
      <td>0.079823</td>
      <td>0.086915</td>
      <td>...</td>
      <td>0.028962</td>
      <td>0.062234</td>
      <td>0.023879</td>
      <td>0.030534</td>
      <td>0.040489</td>
      <td>0.065195</td>
      <td>0.044938</td>
      <td>0.068038</td>
      <td>0.012156</td>
      <td>0.038034</td>
    </tr>
    <tr>
      <th>5</th>
      <td>L</td>
      <td>6</td>
      <td>0.060736</td>
      <td>16.068080</td>
      <td>E</td>
      <td>0.152547</td>
      <td>0.038191</td>
      <td>0.009217</td>
      <td>0.065189</td>
      <td>0.152547</td>
      <td>...</td>
      <td>0.040042</td>
      <td>0.096484</td>
      <td>0.020712</td>
      <td>0.035022</td>
      <td>0.046888</td>
      <td>0.049071</td>
      <td>0.046247</td>
      <td>0.048276</td>
      <td>0.010486</td>
      <td>0.022727</td>
    </tr>
  </tbody>
</table>
<p>6 rows × 26 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fc9f64ed-b8b8-433f-bc51-a92954702041')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fc9f64ed-b8b8-433f-bc51-a92954702041 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fc9f64ed-b8b8-433f-bc51-a92954702041');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  

This dataframe is where the true berteomic magic begins. Each row
corresponds to each residue in the input protein sequence.

Here is a breakdown of some the columns in the dataframe.

- `wt` represents the actual amino acid at the given position \`
- `wtIndex` is just a one-based index of the residue which makes
  plotting easier, may not stick around forever though..-
- `wtScore` is a very interesting and important value. For a given
  protein, one would hope that the model would predict that the masked
  residue would be the same as the wild-type in the sequence. This
  column gives us the actual probability that the model provided for the
  wild type residue at that position.
- `n_effective` is a measure of site-specific variability which gives a
  proxy of how many amino acids could occupy that site and is defined as
  $N_{eff}(i) = exp(-\sum p_{ji} \ln p_{ji})$
- `topAA` is the top scoring amino acid at a given position in the
  protein
- `topAAscore` is the score of the top scoring amino acid at a given
  position in the protein

The remaining columns are simply the probabilities of each possible
amino acid generated by the model when placing a mask at every residue
in the input protein.

# Score sequence

The average score for the wild type sequence and the top sequence are
recorded as following using the `scoreSeq()` function

``` python
print(mendel_berteome.wtSeq, mendel_berteome.wtSeqScore)
```

    MENDEL 0.06513680818699674

``` python
print(mendel_berteome.topAASeq, mendel_berteome.topAASeqScore)
```

    ELELLE 0.12703558564775272

To test the score of another given protein of the same length as the
input provide it to `scoreSeq()`

``` python
mendel_berteome.scoreSeq("LEDNEM")
```

    0.08294893247204337

## Amino acid correlation

For a given berteome dataframe, to investigate how correlated the
predictions of the different amino acids are to each other, the
`aa_correlation()` can be used to generate a correlation dataframe

``` python
mendel_berteome.aa_correlation()
```

  <div id="df-45d530d7-40cf-4d2b-8b2c-4eeb29ebbd58">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>A</th>
      <th>C</th>
      <th>D</th>
      <th>E</th>
      <th>F</th>
      <th>G</th>
      <th>H</th>
      <th>I</th>
      <th>K</th>
      <th>L</th>
      <th>M</th>
      <th>N</th>
      <th>P</th>
      <th>Q</th>
      <th>R</th>
      <th>S</th>
      <th>T</th>
      <th>V</th>
      <th>W</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>A</th>
      <td>1.000000</td>
      <td>0.728715</td>
      <td>0.235810</td>
      <td>-0.389881</td>
      <td>0.879476</td>
      <td>0.295942</td>
      <td>0.745626</td>
      <td>0.281984</td>
      <td>-0.521585</td>
      <td>0.733507</td>
      <td>-0.720196</td>
      <td>-0.611638</td>
      <td>0.079974</td>
      <td>-0.433480</td>
      <td>-0.010743</td>
      <td>0.051074</td>
      <td>-0.411039</td>
      <td>0.833228</td>
      <td>0.585931</td>
      <td>0.854028</td>
    </tr>
    <tr>
      <th>C</th>
      <td>0.728715</td>
      <td>1.000000</td>
      <td>-0.335088</td>
      <td>-0.816557</td>
      <td>0.854113</td>
      <td>0.231246</td>
      <td>0.948530</td>
      <td>0.774245</td>
      <td>-0.042328</td>
      <td>0.466360</td>
      <td>-0.382039</td>
      <td>-0.235091</td>
      <td>0.369492</td>
      <td>0.063831</td>
      <td>0.313224</td>
      <td>0.638680</td>
      <td>0.247716</td>
      <td>0.876382</td>
      <td>0.736406</td>
      <td>0.923179</td>
    </tr>
    <tr>
      <th>D</th>
      <td>0.235810</td>
      <td>-0.335088</td>
      <td>1.000000</td>
      <td>0.765979</td>
      <td>0.084235</td>
      <td>-0.105942</td>
      <td>-0.311789</td>
      <td>-0.822667</td>
      <td>-0.909459</td>
      <td>0.087417</td>
      <td>-0.275036</td>
      <td>-0.582001</td>
      <td>-0.599210</td>
      <td>-0.924921</td>
      <td>-0.890908</td>
      <td>-0.671450</td>
      <td>-0.903985</td>
      <td>0.053578</td>
      <td>-0.545097</td>
      <td>-0.021774</td>
    </tr>
    <tr>
      <th>E</th>
      <td>-0.389881</td>
      <td>-0.816557</td>
      <td>0.765979</td>
      <td>1.000000</td>
      <td>-0.555587</td>
      <td>-0.275369</td>
      <td>-0.756602</td>
      <td>-0.960438</td>
      <td>-0.445065</td>
      <td>-0.449610</td>
      <td>0.096603</td>
      <td>-0.027768</td>
      <td>-0.732525</td>
      <td>-0.612381</td>
      <td>-0.710520</td>
      <td>-0.797273</td>
      <td>-0.600746</td>
      <td>-0.555545</td>
      <td>-0.767344</td>
      <td>-0.570188</td>
    </tr>
    <tr>
      <th>F</th>
      <td>0.879476</td>
      <td>0.854113</td>
      <td>0.084235</td>
      <td>-0.555587</td>
      <td>1.000000</td>
      <td>0.456554</td>
      <td>0.850718</td>
      <td>0.485913</td>
      <td>-0.477462</td>
      <td>0.699525</td>
      <td>-0.622554</td>
      <td>-0.579098</td>
      <td>0.359113</td>
      <td>-0.254101</td>
      <td>-0.072730</td>
      <td>0.316786</td>
      <td>-0.244819</td>
      <td>0.988905</td>
      <td>0.546930</td>
      <td>0.916871</td>
    </tr>
    <tr>
      <th>G</th>
      <td>0.295942</td>
      <td>0.231246</td>
      <td>-0.105942</td>
      <td>-0.275369</td>
      <td>0.456554</td>
      <td>1.000000</td>
      <td>0.469726</td>
      <td>0.397903</td>
      <td>-0.077726</td>
      <td>0.311330</td>
      <td>-0.730925</td>
      <td>0.058535</td>
      <td>0.495876</td>
      <td>0.101607</td>
      <td>0.103240</td>
      <td>-0.197845</td>
      <td>-0.268707</td>
      <td>0.464570</td>
      <td>0.501197</td>
      <td>0.351616</td>
    </tr>
    <tr>
      <th>H</th>
      <td>0.745626</td>
      <td>0.948530</td>
      <td>-0.311789</td>
      <td>-0.756602</td>
      <td>0.850718</td>
      <td>0.469726</td>
      <td>1.000000</td>
      <td>0.780561</td>
      <td>-0.042413</td>
      <td>0.403463</td>
      <td>-0.613985</td>
      <td>-0.096182</td>
      <td>0.331736</td>
      <td>0.020781</td>
      <td>0.334197</td>
      <td>0.428618</td>
      <td>0.133952</td>
      <td>0.884543</td>
      <td>0.852826</td>
      <td>0.949145</td>
    </tr>
    <tr>
      <th>I</th>
      <td>0.281984</td>
      <td>0.774245</td>
      <td>-0.822667</td>
      <td>-0.960438</td>
      <td>0.485913</td>
      <td>0.397903</td>
      <td>0.780561</td>
      <td>1.000000</td>
      <td>0.529274</td>
      <td>0.250579</td>
      <td>-0.168629</td>
      <td>0.251701</td>
      <td>0.680964</td>
      <td>0.638906</td>
      <td>0.732241</td>
      <td>0.718695</td>
      <td>0.641516</td>
      <td>0.519193</td>
      <td>0.815986</td>
      <td>0.560868</td>
    </tr>
    <tr>
      <th>K</th>
      <td>-0.521585</td>
      <td>-0.042328</td>
      <td>-0.909459</td>
      <td>-0.445065</td>
      <td>-0.477462</td>
      <td>-0.077726</td>
      <td>-0.042413</td>
      <td>0.529274</td>
      <td>1.000000</td>
      <td>-0.363198</td>
      <td>0.430711</td>
      <td>0.773596</td>
      <td>0.335641</td>
      <td>0.889436</td>
      <td>0.850882</td>
      <td>0.411445</td>
      <td>0.872259</td>
      <td>-0.447153</td>
      <td>0.317516</td>
      <td>-0.325409</td>
    </tr>
    <tr>
      <th>L</th>
      <td>0.733507</td>
      <td>0.466360</td>
      <td>0.087417</td>
      <td>-0.449610</td>
      <td>0.699525</td>
      <td>0.311330</td>
      <td>0.403463</td>
      <td>0.250579</td>
      <td>-0.363198</td>
      <td>1.000000</td>
      <td>-0.360747</td>
      <td>-0.779561</td>
      <td>0.554168</td>
      <td>-0.037799</td>
      <td>0.062691</td>
      <td>0.196182</td>
      <td>-0.320035</td>
      <td>0.588133</td>
      <td>0.326965</td>
      <td>0.436262</td>
    </tr>
    <tr>
      <th>M</th>
      <td>-0.720196</td>
      <td>-0.382039</td>
      <td>-0.275036</td>
      <td>0.096603</td>
      <td>-0.622554</td>
      <td>-0.730925</td>
      <td>-0.613985</td>
      <td>-0.168629</td>
      <td>0.430711</td>
      <td>-0.360747</td>
      <td>1.000000</td>
      <td>0.161156</td>
      <td>0.038805</td>
      <td>0.444461</td>
      <td>0.054104</td>
      <td>0.430607</td>
      <td>0.575776</td>
      <td>-0.620557</td>
      <td>-0.596739</td>
      <td>-0.652702</td>
    </tr>
    <tr>
      <th>N</th>
      <td>-0.611638</td>
      <td>-0.235091</td>
      <td>-0.582001</td>
      <td>-0.027768</td>
      <td>-0.579098</td>
      <td>0.058535</td>
      <td>-0.096182</td>
      <td>0.251701</td>
      <td>0.773596</td>
      <td>-0.779561</td>
      <td>0.161156</td>
      <td>1.000000</td>
      <td>-0.116805</td>
      <td>0.493948</td>
      <td>0.512856</td>
      <td>-0.030982</td>
      <td>0.583403</td>
      <td>-0.486078</td>
      <td>0.203202</td>
      <td>-0.307124</td>
    </tr>
    <tr>
      <th>P</th>
      <td>0.079974</td>
      <td>0.369492</td>
      <td>-0.599210</td>
      <td>-0.732525</td>
      <td>0.359113</td>
      <td>0.495876</td>
      <td>0.331736</td>
      <td>0.680964</td>
      <td>0.335641</td>
      <td>0.554168</td>
      <td>0.038805</td>
      <td>-0.116805</td>
      <td>1.000000</td>
      <td>0.711239</td>
      <td>0.444692</td>
      <td>0.584902</td>
      <td>0.362906</td>
      <td>0.320287</td>
      <td>0.353894</td>
      <td>0.130560</td>
    </tr>
    <tr>
      <th>Q</th>
      <td>-0.433480</td>
      <td>0.063831</td>
      <td>-0.924921</td>
      <td>-0.612381</td>
      <td>-0.254101</td>
      <td>0.101607</td>
      <td>0.020781</td>
      <td>0.638906</td>
      <td>0.889436</td>
      <td>-0.037799</td>
      <td>0.444461</td>
      <td>0.493948</td>
      <td>0.711239</td>
      <td>1.000000</td>
      <td>0.778680</td>
      <td>0.589466</td>
      <td>0.823069</td>
      <td>-0.252465</td>
      <td>0.281352</td>
      <td>-0.272664</td>
    </tr>
    <tr>
      <th>R</th>
      <td>-0.010743</td>
      <td>0.313224</td>
      <td>-0.890908</td>
      <td>-0.710520</td>
      <td>-0.072730</td>
      <td>0.103240</td>
      <td>0.334197</td>
      <td>0.732241</td>
      <td>0.850882</td>
      <td>0.062691</td>
      <td>0.054104</td>
      <td>0.512856</td>
      <td>0.444692</td>
      <td>0.778680</td>
      <td>1.000000</td>
      <td>0.432140</td>
      <td>0.713219</td>
      <td>-0.081304</td>
      <td>0.706982</td>
      <td>0.066204</td>
    </tr>
    <tr>
      <th>S</th>
      <td>0.051074</td>
      <td>0.638680</td>
      <td>-0.671450</td>
      <td>-0.797273</td>
      <td>0.316786</td>
      <td>-0.197845</td>
      <td>0.428618</td>
      <td>0.718695</td>
      <td>0.411445</td>
      <td>0.196182</td>
      <td>0.430607</td>
      <td>-0.030982</td>
      <td>0.584902</td>
      <td>0.589466</td>
      <td>0.432140</td>
      <td>1.000000</td>
      <td>0.762128</td>
      <td>0.338232</td>
      <td>0.276276</td>
      <td>0.313997</td>
    </tr>
    <tr>
      <th>T</th>
      <td>-0.411039</td>
      <td>0.247716</td>
      <td>-0.903985</td>
      <td>-0.600746</td>
      <td>-0.244819</td>
      <td>-0.268707</td>
      <td>0.133952</td>
      <td>0.641516</td>
      <td>0.872259</td>
      <td>-0.320035</td>
      <td>0.575776</td>
      <td>0.583403</td>
      <td>0.362906</td>
      <td>0.823069</td>
      <td>0.713219</td>
      <td>0.762128</td>
      <td>1.000000</td>
      <td>-0.191152</td>
      <td>0.265527</td>
      <td>-0.089419</td>
    </tr>
    <tr>
      <th>V</th>
      <td>0.833228</td>
      <td>0.876382</td>
      <td>0.053578</td>
      <td>-0.555545</td>
      <td>0.988905</td>
      <td>0.464570</td>
      <td>0.884543</td>
      <td>0.519193</td>
      <td>-0.447153</td>
      <td>0.588133</td>
      <td>-0.620557</td>
      <td>-0.486078</td>
      <td>0.320287</td>
      <td>-0.252465</td>
      <td>-0.081304</td>
      <td>0.338232</td>
      <td>-0.191152</td>
      <td>1.000000</td>
      <td>0.557270</td>
      <td>0.944824</td>
    </tr>
    <tr>
      <th>W</th>
      <td>0.585931</td>
      <td>0.736406</td>
      <td>-0.545097</td>
      <td>-0.767344</td>
      <td>0.546930</td>
      <td>0.501197</td>
      <td>0.852826</td>
      <td>0.815986</td>
      <td>0.317516</td>
      <td>0.326965</td>
      <td>-0.596739</td>
      <td>0.203202</td>
      <td>0.353894</td>
      <td>0.281352</td>
      <td>0.706982</td>
      <td>0.276276</td>
      <td>0.265527</td>
      <td>0.557270</td>
      <td>1.000000</td>
      <td>0.694811</td>
    </tr>
    <tr>
      <th>Y</th>
      <td>0.854028</td>
      <td>0.923179</td>
      <td>-0.021774</td>
      <td>-0.570188</td>
      <td>0.916871</td>
      <td>0.351616</td>
      <td>0.949145</td>
      <td>0.560868</td>
      <td>-0.325409</td>
      <td>0.436262</td>
      <td>-0.652702</td>
      <td>-0.307124</td>
      <td>0.130560</td>
      <td>-0.272664</td>
      <td>0.066204</td>
      <td>0.313997</td>
      <td>-0.089419</td>
      <td>0.944824</td>
      <td>0.694811</td>
      <td>1.000000</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-45d530d7-40cf-4d2b-8b2c-4eeb29ebbd58')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-45d530d7-40cf-4d2b-8b2c-4eeb29ebbd58 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-45d530d7-40cf-4d2b-8b2c-4eeb29ebbd58');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  

## Most probable variants

`berteome` can also be used to generate single residue substitution
variants for the top k amino acids for a given residue in a protein. To
generate the top 3 mutational variants for `MENDEL` the `generate`
submodule can be loaded and used as follows:

``` python
from berteome import generate
```

``` python
generate.top_k_variants(mendel_berteome, 3)
```

  <div id="df-fdeaf299-cd5f-4003-9758-91e750cc9b48">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>sub</th>
      <th>seq</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0subE</td>
      <td>EENDEL</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0subK</td>
      <td>KENDEL</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0subN</td>
      <td>NENDEL</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1subL</td>
      <td>MLNDEL</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1subK</td>
      <td>MKNDEL</td>
    </tr>
    <tr>
      <th>5</th>
      <td>1subI</td>
      <td>MINDEL</td>
    </tr>
    <tr>
      <th>6</th>
      <td>2subE</td>
      <td>MEEDEL</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2subD</td>
      <td>MEDDEL</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2subL</td>
      <td>MELDEL</td>
    </tr>
    <tr>
      <th>9</th>
      <td>3subL</td>
      <td>MENLEL</td>
    </tr>
    <tr>
      <th>10</th>
      <td>3subK</td>
      <td>MENKEL</td>
    </tr>
    <tr>
      <th>11</th>
      <td>3subE</td>
      <td>MENEEL</td>
    </tr>
    <tr>
      <th>12</th>
      <td>4subL</td>
      <td>MENDLL</td>
    </tr>
    <tr>
      <th>13</th>
      <td>4subD</td>
      <td>MENDDL</td>
    </tr>
    <tr>
      <th>14</th>
      <td>4subI</td>
      <td>MENDIL</td>
    </tr>
    <tr>
      <th>15</th>
      <td>5subE</td>
      <td>MENDEE</td>
    </tr>
    <tr>
      <th>16</th>
      <td>5subK</td>
      <td>MENDEK</td>
    </tr>
    <tr>
      <th>17</th>
      <td>5subN</td>
      <td>MENDEN</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fdeaf299-cd5f-4003-9758-91e750cc9b48')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fdeaf299-cd5f-4003-9758-91e750cc9b48 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fdeaf299-cd5f-4003-9758-91e750cc9b48');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  

This returns a dataframe with L x k possible single amino acid
variants. - `sub` is the substitution id that indicates which residue
was substitued with what amino acid following the pattern
`{residue_number}sub{substituted_amino_acid}` - `seq` is the new variant
sequence.

# Random sequences

If you’d like to take the amino acid probabilities at each residue
position to randomly generate proteins from the probability dataframe
provided by berteome, you can use `n_random_seqs`

``` python
generate.n_random_seqs(mendel_berteome, 10)
```

  <div id="df-f528d1bb-cefa-4897-b695-1cc7bc7b7734">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seq</th>
      <th>score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>QSSESS</td>
      <td>0.058610</td>
    </tr>
    <tr>
      <th>1</th>
      <td>NDHGWH</td>
      <td>0.034827</td>
    </tr>
    <tr>
      <th>2</th>
      <td>SAKCVK</td>
      <td>0.056908</td>
    </tr>
    <tr>
      <th>3</th>
      <td>PLRLMA</td>
      <td>0.056149</td>
    </tr>
    <tr>
      <th>4</th>
      <td>IQVQFS</td>
      <td>0.049592</td>
    </tr>
    <tr>
      <th>5</th>
      <td>MTDEIA</td>
      <td>0.081339</td>
    </tr>
    <tr>
      <th>6</th>
      <td>PVFAVM</td>
      <td>0.044242</td>
    </tr>
    <tr>
      <th>7</th>
      <td>NMSSVW</td>
      <td>0.050866</td>
    </tr>
    <tr>
      <th>8</th>
      <td>DYYIIQ</td>
      <td>0.047647</td>
    </tr>
    <tr>
      <th>9</th>
      <td>GQLEPM</td>
      <td>0.053943</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-f528d1bb-cefa-4897-b695-1cc7bc7b7734')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">
        
  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-f528d1bb-cefa-4897-b695-1cc7bc7b7734 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-f528d1bb-cefa-4897-b695-1cc7bc7b7734');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  

- `seq` is the randomly generated sequence
- `score` is the average score of the amino acids chosen in the randomly
  generated sequence

## Plotting

# Development

To build the library run the following

    nbdev export

Then, pip install in a development environment

    pip install -e '.[dev]'

I do quite a bit of work on a chromebook, which allows for doing stuff
on github through codespace and also on google colab. To install a
particular commit hash of `berteome` you can do the following:

``` python
!pip uninstall berteome
```

    Found existing installation: berteome 0.1.5
    Uninstalling berteome-0.1.5:
      Would remove:
        /usr/local/lib/python3.8/dist-packages/berteome-0.1.5.dist-info/*
        /usr/local/lib/python3.8/dist-packages/berteome/*
    Proceed (y/n)? y
      Successfully uninstalled berteome-0.1.5

``` python
!pip install "berteome @ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4"
```

    Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
    Collecting berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4
      Cloning https://github.com/tijeco/berteome (to revision b10ac07f31269a13a1bf8af437ca762b917b68a4) to /tmp/pip-install-q34jqt3g/berteome_b3916552555d419ba5765fe58f1d0bde
      Running command git clone -q https://github.com/tijeco/berteome /tmp/pip-install-q34jqt3g/berteome_b3916552555d419ba5765fe58f1d0bde
      Running command git rev-parse -q --verify 'sha^b10ac07f31269a13a1bf8af437ca762b917b68a4'
      Running command git fetch -q https://github.com/tijeco/berteome b10ac07f31269a13a1bf8af437ca762b917b68a4
      Running command git checkout -q b10ac07f31269a13a1bf8af437ca762b917b68a4
    Requirement already satisfied: pip in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (21.1.3)
    Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (21.3)
    Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.3.5)
    Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.21.6)
    Requirement already satisfied: seqlogo in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (5.29.8)
    Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (4.25.1)
    Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.13.0+cu116)
    Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (3.0.9)
    Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2.8.2)
    Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2022.6)
    Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.15.0)
    Requirement already satisfied: weblogo in /usr/local/lib/python3.8/dist-packages (from seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (3.7.12)
    Requirement already satisfied: pytest in /usr/local/lib/python3.8/dist-packages (from seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (3.6.4)
    Requirement already satisfied: ghostscript in /usr/local/lib/python3.8/dist-packages (from seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (0.7)
    Requirement already satisfied: setuptools>=38.6.0 in /usr/local/lib/python3.8/dist-packages (from ghostscript->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (57.4.0)
    Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from pytest->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.11.0)
    Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.8/dist-packages (from pytest->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.4.1)
    Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.8/dist-packages (from pytest->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (0.7.1)
    Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.8/dist-packages (from pytest->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (22.1.0)
    Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytest->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (9.0.0)
    Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (4.4.0)
    Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (0.11.1)
    Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (0.13.2)
    Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (6.0)
    Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2022.6.2)
    Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2.23.0)
    Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (4.64.1)
    Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (3.8.2)
    Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (3.0.4)
    Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2022.12.7)
    Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.24.3)
    Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (2.10)
    Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from weblogo->seqlogo->berteome@ git+https://github.com/tijeco/berteome@b10ac07f31269a13a1bf8af437ca762b917b68a4) (1.7.3)
    Building wheels for collected packages: berteome
      Building wheel for berteome (setup.py) ... done
      Created wheel for berteome: filename=berteome-0.1.5-py3-none-any.whl size=17286 sha256=caf9b421ccfba8fb2008f42ebe0c23f3414fa7a2006dcae7516ecfebf907bc82
      Stored in directory: /root/.cache/pip/wheels/b0/b5/72/b41755d52ff8d6a22c281b1b0863c6e1501a41839762b69855
    Successfully built berteome
    Installing collected packages: berteome
    Successfully installed berteome-0.1.5

    Unable to display output for mime type(s): application/vnd.colab-display-data+json
