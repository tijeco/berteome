{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp berteome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from transformers import BertTokenizer, BertForMaskedLM, EsmTokenizer, EsmForMaskedLM\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelPredDF():\n",
    "    def __init__(self, seq, tokenizer, model):\n",
    "        self.aas = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "        predDict = self.predictionDict(seq, tokenizer, model)\n",
    "        self.df = pd.DataFrame.from_dict(predDict, orient = \"index\", columns = list(self.aas))\n",
    "        self.df = self.df.div(self.df.sum(axis=1),axis=0)\n",
    "        self.df.insert(0, \"wt\",list(seq))\n",
    "        self.df.insert(1, \"wtIndex\",list(range(1,len(seq)+1)))\n",
    "        wtScore = self.scoreCol(\"wt\")\n",
    "        self.df.insert(2, \"wtScore\",wtScore)\n",
    "        self.df.insert(3, \"n_effective\", self.n_effective())\n",
    "        self.df.insert(4, \"topAA\",self.topAA())\n",
    "        topAAscore = self.scoreCol(\"topAA\")\n",
    "        self.df.insert(5, \"topAAscore\", topAAscore)\n",
    "        \n",
    "        self.wtSeq = ''.join(list(self.df[\"wt\"]))\n",
    "        self.wtSeqScore = self.scoreSeq(self.wtSeq)\n",
    "\n",
    "        self.topAASeq = ''.join(list(self.df[\"topAA\"]))\n",
    "        self.topAASeqScore = self.scoreSeq(self.topAASeq)\n",
    "\n",
    "    def predictionDict(self, seq, tokenizer, model):\n",
    "      naturalAAIndices = naturalAAIndex(self.aas,tokenizer)\n",
    "      predDict = {}\n",
    "      for wtIndex in range(len(seq)):\n",
    "        maskedSeq = tokenizeSeq(seq, tokenizer, mask_index = wtIndex)\n",
    "        seq_logits = run_model(model, maskedSeq)\n",
    "        seq_probs = logits2prob(seq_logits)\n",
    "        predDict[wtIndex] = [i.item() for i in getNatProbs(naturalAAIndices, seq_probs[0, wtIndex +1])]\n",
    "      return predDict\n",
    "\n",
    "    def scoreCol(self, col):\n",
    "        score = []\n",
    "        for row in self.df.to_dict(orient=\"records\"):\n",
    "\t        col_aa = row[col]\n",
    "\t        score.append(row[col_aa])\n",
    "        return score\n",
    "    \n",
    "    def scoreSeq(self, seq):\n",
    "      seqScore = 0\n",
    "      if len(seq) != len(self.df):\n",
    "        raise Exception(f\"The provided sequence is of length {len(seq)}, but berteome expected {len(self.df)}\")\n",
    "      for index, row in self.df.iterrows():\n",
    "        seqScore += row[seq[index]]\n",
    "      return seqScore / len(self.df)\n",
    "\n",
    "\n",
    "    def n_effective(self):\n",
    "      df_aas = self.df[list(self.aas)]\n",
    "      entropy =  -(np.log(df_aas) * df_aas)\n",
    "      return np.exp(entropy.sum(axis = 1))\n",
    "\n",
    "    def topAA(self):\n",
    "      return self.df[list(self.aas)].idxmax(axis=1)\n",
    "                            \n",
    "    def aa_correlation(self):\n",
    "      return self.df[list(self.aas)].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class modelLoader():\n",
    "  def __init__(self):\n",
    "    self.supported_model_dict = {\n",
    "        \"Rostlab/prot_bert\" : self.token_model_dict(\"prot_bert\"),\n",
    "        \"facebook/esm2_t33_650M_UR50D\" : self.token_model_dict(\"esm\"),\n",
    "        \"facebook/esm1b_t33_650M_UR50S\": self.token_model_dict(\"esm\")\n",
    "    }\n",
    "    self.supported_models = list(self.supported_model_dict.keys())\n",
    "\n",
    "  \n",
    "  def token_model_dict(self, model_name):\n",
    "    if model_name == \"prot_bert\":\n",
    "      tokenModelDict = {\"tokenizer\":BertTokenizer, \"model\":BertForMaskedLM}\n",
    "    if model_name == \"esm\":\n",
    "      tokenModelDict = {\"tokenizer\":EsmTokenizer, \"model\":EsmForMaskedLM}\n",
    "    return tokenModelDict\n",
    "  \n",
    "  def load_model(self, model_path):\n",
    "    tokenizerLM = self.supported_model_dict[model_path][\"tokenizer\"]\n",
    "    maskedLM = self.supported_model_dict[model_path][\"model\"]\n",
    "    tokenizer = tokenizerLM.from_pretrained(model_path)\n",
    "    model = maskedLM.from_pretrained(model_path)\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "def run_model(model, inputs):\n",
    "  with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "  return logits\n",
    "\n",
    "def logits2prob(logits):\n",
    "  return torch.softmax(logits,dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def maskifySeq(seq, tokenizer, i):\n",
    "    seqList = list(seq)\n",
    "    if i != None:\n",
    "      seqList[i] = tokenizer.mask_token \n",
    "    return \" \".join(seqList)\n",
    "\n",
    "def tokenizeSeq(seq, tokenizer, mask_index = None, return_tensors = \"pt\"):\n",
    "  maskified_seq = maskifySeq(seq, tokenizer, mask_index)\n",
    "  return tokenizer(maskified_seq, return_tensors=return_tensors)\n",
    "\n",
    "def naturalAAIndex(aas, tokenizer):\n",
    "    return tokenizeSeq(aas, tokenizer, return_tensors=None)[\"input_ids\"][1:-1]\n",
    "\n",
    "def getNatProbs(natAAList,probList):\n",
    "    natProbList = []\n",
    "    for natAAIndex in natAAList:\n",
    "      natProbList.append(probList[natAAIndex])\n",
    "    return natProbList"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6 (main, Aug 10 2022, 11:40:04) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
