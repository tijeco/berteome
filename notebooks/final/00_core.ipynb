{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp berteome\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    " #export\n",
    "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
    "model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
    "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def spacifySeq(seq):\n",
    "  return \"\".join([ aa +\" \" for aa in seq]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert spacifySeq(\"MENDEL\") == \"M E N D E L\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def maskifySeq(seq, pos, mask=\"[MASK]\"):\n",
    "  seqList = seq.split()\n",
    "  seqList[pos] = mask\n",
    "  return \"\".join(aa +\" \" for aa in seqList).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert  maskifySeq(\"M E N D E L\",3) == 'M E N [MASK] E L'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def allResidueCoordinates(seq,residue):\n",
    "  return [i for i, x in enumerate(seq) if x == residue]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert allResidueCoordinates(\"MENDEL\",\"E\") == [1,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def allResiduePredictions(seq):\n",
    "  spaceSeq = spacifySeq(seq)\n",
    "  \n",
    "  posPredictions = []\n",
    "  for aaPos in range(len(seq)):\n",
    "    aa = seq[aaPos]\n",
    "    maskPosSeq = maskifySeq(spaceSeq, aaPos)\n",
    "    prediction = unmasker(maskPosSeq, top_k=30)\n",
    "    posPredictions.append(prediction)\n",
    "  return posPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert len(allResiduePredictions(\"MENDEL\")) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert allResiduePredictions(\"MENDEL\")[0][0][\"token_str\"] == \"E\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getTopSeq(allPredictions):\n",
    "  topSeq = \"\"\n",
    "  for aaPred in allPredictions:    \n",
    "    topSeq += aaPred[0][\"token_str\"]\n",
    "  return topSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def residuePredictionScore(allPredictions, seq):\n",
    "  residueScoreDict = {\n",
    "      \"wt\":list(seq),\n",
    "      \"wtIndex\":list(range(len(seq)+1))[1:],\n",
    "      \"wtScore\":[],\n",
    "      \"A\":[],\n",
    "      \"C\":[],\n",
    "      \"D\":[],\n",
    "      \"E\":[],\n",
    "      \"F\":[],\n",
    "      \"G\":[],\n",
    "      \"H\":[],\n",
    "      \"I\":[],\n",
    "      \"K\":[],\n",
    "      \"L\":[],\n",
    "      \"M\":[],\n",
    "      \"N\":[],\n",
    "      \"P\":[],\n",
    "      \"Q\":[],\n",
    "      \"R\":[],\n",
    "      \"S\":[],\n",
    "      \"T\":[],\n",
    "      \"V\":[],\n",
    "      \"W\":[],\n",
    "      \"Y\":[]\n",
    "  }\n",
    "  for aaPredPos in range(len(allPredictions)):\n",
    "    aaPred = allPredictions[aaPredPos]\n",
    "    wtAA = seq[aaPredPos]\n",
    "    for predRank in range(len(aaPred)):\n",
    "      posPred = aaPred[predRank]\n",
    "      predAA = posPred[\"token_str\"]\n",
    "      # print(predRank, posPred[\"token_str\"])\n",
    "      if predAA in residueScoreDict:\n",
    "        residueScoreDict[predAA].append(posPred[\"score\"])\n",
    "        if predAA == wtAA:\n",
    "          residueScoreDict[\"wtScore\"].append(posPred[\"score\"])\n",
    "\n",
    "  residueScoreDF = pd.DataFrame.from_dict(residueScoreDict)\n",
    "  return residueScoreDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def hasNonStandardAA(seq, alphabet=\"ACDEFGHIKLMNPQRSTVWY\"):\n",
    "\treturn (set(seq) - set(alphabet)) != set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasNonStandardAA(\"MENDEL\") == False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified approach to interface with both ProtBERT and ESM\n",
    "\n",
    "I will likely just leave the previous few functions alone so that it will continue to be supported, luckily I have unittests for the helper functions so I will be sure not to break those either."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def childrenPredictions(allPredictions,seq):\n",
    "  residues = \"ACDEFGHIKLMNPQRSTVQY\"\n",
    "\n",
    "  parentScoreDF = residuePredictionScore(allPredictions, seq)\n",
    "  parentScoreDF[\"seq\"] = seq\n",
    "  scoreDFs = [parentScoreDF]\n",
    "  for prediction in allPredictions:\n",
    "    top5predictions = prediction[:5]\n",
    "    for child in top5predictions:\n",
    "        childSeq = child[\"sequence\"].replace(\" \",\"\")\n",
    "        if childSeq != seq:\n",
    "          if not hasNonStandardAA(childSeq):\n",
    "            # print(childSeq)\n",
    "            childPredictions = allResiduePredictions(childSeq)\n",
    "            childScoreDF = residuePredictionScore(childPredictions, childSeq)\n",
    "            childScoreDF[\"seq\"] = childSeq\n",
    "            scoreDFs.append(childScoreDF)\n",
    "  return pd.concat(scoreDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def childrenPPM(childrenScores):\n",
    "  childrenScoreSum = childrenScores.groupby([\"wtIndex\"]).sum()\n",
    "  childrenScoreSum = childrenScoreSum[childrenScoreSum.columns[1:]]\n",
    "  childrenScorePPM = childrenScoreSum.div(childrenScoreSum.sum(axis=1),axis=0)\n",
    "  return childrenScorePPM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.2 64-bit",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
