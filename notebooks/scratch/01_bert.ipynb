{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "oFujps400ZZq",
        "outputId": "1c679b96-b777-485d-b97a-b455b7f5fd4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.8.2)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n",
            "\u001b[K     |████████████████████████████████| 182 kB 42.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.11.1 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i_pP0q5g0R3q"
      },
      "outputs": [],
      "source": [
        "# default_exp prot_bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVM60K4O0R3w"
      },
      "outputs": [],
      "source": [
        "#hide\n",
        "from nbdev.showdoc import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "g08Fr4EP0R3x"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "from transformers import BertForMaskedLM, BertTokenizer, pipeline\n",
        "import torch\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert new approach"
      ],
      "metadata": {
        "id": "OyOOJ76c0mH0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class modelPredDF():\n",
        "    def __init__(self, predDict, seq, aas):\n",
        "        self.predDf = pd.DataFrame.from_dict(predDict, orient = \"index\", columns = list(aas))\n",
        "        self.predDf = self.predDf.div(self.predDf.sum(axis=1),axis=0)\n",
        "        self.predDf.insert(0, \"wt\",list(seq))\n",
        "        self.predDf.insert(1, \"wtIndex\",list(range(1,len(seq)+1)))\n",
        "        wtScore = self.wtScoreCol()\n",
        "        self.predDf.insert(2, \"wtScore\",wtScore)\n",
        "\n",
        "    def wtScoreCol(self):\n",
        "        wtScore = []\n",
        "        for row in self.predDf.to_dict(orient=\"records\"):\n",
        "\t        wt = row[\"wt\"]\n",
        "\t        wtScore.append(row[wt])\n",
        "        return wtScore"
      ],
      "metadata": {
        "id": "E6Y-Fy_E6C8m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_path, tokenizerLM, maskedLM):\n",
        "  tokenizer = tokenizerLM.from_pretrained(model_path)\n",
        "  model = maskedLM.from_pretrained(model_path)\n",
        "  return tokenizer, model"
      ],
      "metadata": {
        "id": "m3Fa0LTR0ouJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hmm, I'm wondering how crazy it would be to have this be generalized to the point where if you just provide the values for tokenizerLM and maskedLM that it could do a from transformers import tokenizerLM, maskedLM?? That sounds like crazy talk.."
      ],
      "metadata": {
        "id": "vmLU2rR_1Wxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer, bert_model = load_model(\"Rostlab/prot_bert\",BertTokenizer,BertForMaskedLM)"
      ],
      "metadata": {
        "id": "sFBEsD1U03mD",
        "outputId": "eb7f0e0d-0d1f-4c90-f4a7-8dd7d4b073f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_model(model, inputs):\n",
        "  with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "  return logits"
      ],
      "metadata": {
        "id": "0iM4dwG20yZB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer.mask_token"
      ],
      "metadata": {
        "id": "Ik7HtXw21z5q",
        "outputId": "62718681-cfb0-428b-a2ca-b5a090dead0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[MASK]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_tokenizer(\"M E N [MASK] E L\")"
      ],
      "metadata": {
        "id": "qRx-0hHd2KdN",
        "outputId": "616cf280-fc91-4dbe-f455-e89cde2f81ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 21, 9, 17, 4, 9, 5, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def maskifySeq(seq, tokenizer, i , sep=\"\"):\n",
        "    seqList = list(seq)\n",
        "    if i != None:\n",
        "      seqList[i] = tokenizer.mask_token \n",
        "      return sep.join(seqList)"
      ],
      "metadata": {
        "id": "PS9ba9E02ekU"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizeSeq(seq, tokenizer, mask_index = None, sep=\"\", return_tensors = \"pt\"):\n",
        "  maskified_seq = maskifySeq(seq, tokenizer, mask_index, sep)\n",
        "  return tokenizer(maskified_seq, return_tensors=return_tensors)"
      ],
      "metadata": {
        "id": "P_B8-I5C3AsF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mendel_mask3 = tokenizeSeq(\"MENDEL\", bert_tokenizer, mask_index=3, sep = \" \")"
      ],
      "metadata": {
        "id": "NcX74fwm3Fef"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_model(bert_model, mendel_mask3)"
      ],
      "metadata": {
        "id": "k8Gh-3K26NH2",
        "outputId": "57173ff0-2262-4c9b-8d16-103fe110ae0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.9025e+01, -1.9418e+01, -1.9070e+01, -2.0259e+01, -2.1078e+01,\n",
              "           6.8966e-01, -5.8320e-02,  9.9683e-02,  1.1744e-01,  9.2746e-01,\n",
              "           1.7481e-01,  2.6523e-01,  1.0348e+00,  3.9002e-01, -1.5987e-01,\n",
              "           9.6185e-02, -7.2865e-01,  2.0590e-01,  1.6183e-01, -6.3175e-01,\n",
              "          -8.3162e-01,  2.3495e-01, -8.9098e-01, -1.4568e+00, -1.2295e+00,\n",
              "          -5.1355e+00, -1.8929e+01, -1.8691e+01, -1.8911e+01, -1.9173e+01],\n",
              "         [-1.8777e+01, -1.9759e+01, -1.9174e+01, -1.7491e+01, -2.1409e+01,\n",
              "           4.5803e-01, -1.3080e-01, -4.1512e-01, -8.9476e-02,  4.4306e-01,\n",
              "          -2.1111e-01, -2.7136e-01,  1.9480e-01, -3.5983e-01, -4.5520e-01,\n",
              "          -4.6519e-01, -1.1010e+00, -3.5952e-01, -4.2683e-01, -8.3092e-01,\n",
              "          -1.0543e+00,  3.9943e+00, -1.4092e+00, -1.9026e+00, -1.7119e+00,\n",
              "          -3.4918e+00, -1.7906e+01, -1.8299e+01, -1.9515e+01, -1.9495e+01],\n",
              "         [-2.1036e+01, -2.1122e+01, -2.1379e+01, -1.9386e+01, -2.2437e+01,\n",
              "           3.5269e-01, -3.1851e-01, -2.9133e-01, -6.3890e-02,  3.8855e+00,\n",
              "          -1.5753e-01, -9.1192e-02,  5.9056e-01, -1.3770e-01, -4.4542e-01,\n",
              "          -3.9613e-01, -9.5274e-01, -8.8464e-02, -5.1500e-01, -8.0173e-01,\n",
              "          -1.1351e+00, -5.8981e-01, -1.4773e+00, -1.6704e+00, -1.7396e+00,\n",
              "          -6.8102e+00, -2.1193e+01, -2.0686e+01, -2.0735e+01, -2.1072e+01],\n",
              "         [-1.9803e+01, -2.0228e+01, -1.9928e+01, -1.8893e+01, -2.2110e+01,\n",
              "           5.1073e-01, -1.9778e-01, -2.6359e-01,  1.5819e-01,  5.7197e-01,\n",
              "          -1.5409e-01,  2.0408e-01,  4.7740e-01, -9.9441e-02, -1.7263e-01,\n",
              "          -2.7074e-01, -1.0369e+00,  3.4789e+00, -5.2727e-01, -5.4677e-01,\n",
              "          -8.3721e-01, -2.1086e-01, -1.3191e+00, -1.6532e+00, -1.6432e+00,\n",
              "          -6.7966e+00, -1.9901e+01, -2.0050e+01, -2.0100e+01, -2.0158e+01],\n",
              "         [-1.9460e+01, -1.9411e+01, -1.9232e+01, -1.9537e+01, -2.0949e+01,\n",
              "           9.9683e-01,  4.4310e-02,  3.2844e-01,  3.8115e-01,  7.6128e-01,\n",
              "           4.3701e-01,  5.9918e-01,  8.1954e-01,  1.3825e-01,  2.1165e-01,\n",
              "           1.0913e-01, -2.2883e-01,  4.1262e-01, -1.4244e-02, -1.3074e-02,\n",
              "          -4.1456e-01, -4.4337e-03, -8.7034e-01, -1.1118e+00, -1.3088e+00,\n",
              "          -6.3523e+00, -1.9144e+01, -1.9260e+01, -1.9367e+01, -1.9453e+01],\n",
              "         [-2.0983e+01, -2.1118e+01, -2.1276e+01, -1.9275e+01, -2.2573e+01,\n",
              "           4.9689e-01, -5.1976e-01, -3.4544e-01, -5.9994e-02,  3.5064e+00,\n",
              "           6.4620e-02,  1.6180e-01,  2.1261e-01, -2.7679e-01, -3.4769e-01,\n",
              "          -3.3573e-01, -7.2581e-01,  8.2612e-03, -5.4236e-01, -3.0897e-01,\n",
              "          -6.9502e-01, -8.9034e-01, -1.0627e+00, -1.3415e+00, -1.6691e+00,\n",
              "          -6.8331e+00, -2.1251e+01, -2.0741e+01, -2.0885e+01, -2.1180e+01],\n",
              "         [-1.9787e+01, -1.8531e+01, -1.8519e+01, -2.0940e+01, -1.9027e+01,\n",
              "           3.4769e+00, -5.5560e-01, -5.0492e-01, -1.7032e-01,  4.2036e-01,\n",
              "          -3.0500e-01,  1.4673e-01,  5.9021e-01, -3.1069e-01, -4.3780e-01,\n",
              "          -4.9559e-01, -1.3194e+00,  2.0662e-01, -6.2130e-01, -8.2521e-01,\n",
              "          -9.5772e-01, -4.7233e-01, -1.5121e+00, -1.9627e+00, -1.9238e+00,\n",
              "          -6.9596e+00, -1.8058e+01, -1.9786e+01, -1.8690e+01, -1.8938e+01],\n",
              "         [-1.9305e+01, -1.9314e+01, -1.9049e+01, -1.9723e+01, -2.0850e+01,\n",
              "           9.6479e-01,  1.5695e-02, -3.9074e-02,  4.7910e-01,  9.7654e-01,\n",
              "           4.3611e-01,  5.3591e-01,  9.0167e-01,  1.1169e-01,  1.3834e-01,\n",
              "           2.7435e-02, -3.4813e-01,  4.2852e-01,  6.3045e-02,  1.8992e-02,\n",
              "          -3.5895e-01, -1.8571e-01, -8.6704e-01, -1.1596e+00, -1.3700e+00,\n",
              "          -6.4809e+00, -1.9207e+01, -1.9147e+01, -1.9260e+01, -1.9189e+01]]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it seems like I'm getting to a decent generalized approach that works for both ESM and BERT. They both have different mask tokens, which can be inherited from their respective tokenizers, they also have different separators (BERT expects it to be space separated?? It's strange, I don't know if ESM supports space separated?? I also don't know if the separator is inherited from the tokenizer.."
      ],
      "metadata": {
        "id": "upAN1TpV4wkV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def naturalAAIndex(aas, tokenizer, sep = \"\"):\n",
        "    return tokenizeSeq(aas, tokenizer, return_tensors=None, sep = sep)[\"input_ids\"][1:-1]"
      ],
      "metadata": {
        "id": "9uOyc8N-64BU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getNatProbs(natAAList,probList):\n",
        "    natProbList = []\n",
        "    for natAAIndex in natAAList:\n",
        "      natProbList.append(probList[natAAIndex])\n",
        "    return natProbList"
      ],
      "metadata": {
        "id": "DgEDzt_x64pn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logits2prob(logits):\n",
        "  return torch.softmax(logits,dim=2)"
      ],
      "metadata": {
        "id": "Dl2Wkwmp65D7"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naturalAAIndex(\"ACDEFGHIKLMNPQRSTVWY\",bert_tokenizer, sep = \" \")\n"
      ],
      "metadata": {
        "id": "rymB0YLj73sK",
        "outputId": "d02131fe-edc4-4bb4-fe2e-630523c73392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 23, 14, 9, 19, 7, 22, 11, 12, 5, 21, 17, 16, 18, 13, 10, 15, 8, 24, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bertPredictionDF(seq, tokenizer, model, aas = \"ACDEFGHIKLMNPQRSTVWY\"):\n",
        "  naturalAAIndices = naturalAAIndex(aas,tokenizer, sep = \" \")\n",
        "  bertPredDict = {}\n",
        "  for wtIndex in range(len(seq)):\n",
        "    maskedSeq = tokenizeSeq(seq, tokenizer, mask_index = wtIndex, sep = \" \")\n",
        "    seq_logits = run_model(model, maskedSeq)\n",
        "    seq_probs = logits2prob(seq_logits)\n",
        "    bertPredDict[wtIndex] = [i.item() for i in getNatProbs(naturalAAIndices, seq_probs[0, wtIndex +1])]\n",
        "  bertPredDF = modelPredDF(bertPredDict, seq, aas).predDf\n",
        "  return bertPredDF"
      ],
      "metadata": {
        "id": "8ieTgwkA5sX3"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bertPredictionDF(\"MENDEL\", bert_tokenizer, bert_model)"
      ],
      "metadata": {
        "id": "Wtod0mHV7hPS",
        "outputId": "14fcd7c7-cd66-4176-b042-14a1cfa796a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  wt  wtIndex   wtScore         A         C         D         E         F  \\\n",
              "0  M        1  0.076602  0.036697  0.011504  0.048245  0.118906  0.024072   \n",
              "1  E        2  0.074830  0.045721  0.015662  0.041921  0.074830  0.037153   \n",
              "2  N        3  0.041990  0.043564  0.009685  0.162590  0.184364  0.033782   \n",
              "3  D        4  0.049748  0.042083  0.013244  0.049748  0.086194  0.039736   \n",
              "4  E        5  0.086915  0.046641  0.018770  0.079822  0.086915  0.050638   \n",
              "5  L        6  0.060736  0.038191  0.009217  0.065189  0.152547  0.020950   \n",
              "\n",
              "          G         H  ...         M         N         P         Q         R  \\\n",
              "0  0.039202  0.012621  ...  0.076602  0.072661  0.024722  0.038672  0.043105   \n",
              "1  0.044325  0.018264  ...  0.043581  0.062667  0.025277  0.036911  0.055543   \n",
              "2  0.044661  0.012355  ...  0.041484  0.041990  0.019992  0.025515  0.029433   \n",
              "3  0.055911  0.016861  ...  0.040080  0.060822  0.032024  0.039689  0.046228   \n",
              "4  0.050466  0.022397  ...  0.028962  0.062234  0.023879  0.030534  0.040489   \n",
              "5  0.049525  0.013955  ...  0.040042  0.096484  0.020712  0.035022  0.046888   \n",
              "\n",
              "          S         T         V         W         Y  \n",
              "0  0.070280  0.056544  0.049927  0.007781  0.021699  \n",
              "1  0.064425  0.049955  0.056789  0.012691  0.029893  \n",
              "2  0.048106  0.030303  0.054742  0.007430  0.024924  \n",
              "3  0.062323  0.044901  0.058937  0.010875  0.026596  \n",
              "4  0.065195  0.044938  0.068038  0.012156  0.038034  \n",
              "5  0.049071  0.046247  0.048276  0.010486  0.022727  \n",
              "\n",
              "[6 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06ca4a4e-fb6c-4116-9d5a-d009a9039224\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wt</th>\n",
              "      <th>wtIndex</th>\n",
              "      <th>wtScore</th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>...</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>0.076602</td>\n",
              "      <td>0.036697</td>\n",
              "      <td>0.011504</td>\n",
              "      <td>0.048245</td>\n",
              "      <td>0.118906</td>\n",
              "      <td>0.024072</td>\n",
              "      <td>0.039202</td>\n",
              "      <td>0.012621</td>\n",
              "      <td>...</td>\n",
              "      <td>0.076602</td>\n",
              "      <td>0.072661</td>\n",
              "      <td>0.024722</td>\n",
              "      <td>0.038672</td>\n",
              "      <td>0.043105</td>\n",
              "      <td>0.070280</td>\n",
              "      <td>0.056544</td>\n",
              "      <td>0.049927</td>\n",
              "      <td>0.007781</td>\n",
              "      <td>0.021699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E</td>\n",
              "      <td>2</td>\n",
              "      <td>0.074830</td>\n",
              "      <td>0.045721</td>\n",
              "      <td>0.015662</td>\n",
              "      <td>0.041921</td>\n",
              "      <td>0.074830</td>\n",
              "      <td>0.037153</td>\n",
              "      <td>0.044325</td>\n",
              "      <td>0.018264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043581</td>\n",
              "      <td>0.062667</td>\n",
              "      <td>0.025277</td>\n",
              "      <td>0.036911</td>\n",
              "      <td>0.055543</td>\n",
              "      <td>0.064425</td>\n",
              "      <td>0.049955</td>\n",
              "      <td>0.056789</td>\n",
              "      <td>0.012691</td>\n",
              "      <td>0.029893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>0.041990</td>\n",
              "      <td>0.043564</td>\n",
              "      <td>0.009685</td>\n",
              "      <td>0.162590</td>\n",
              "      <td>0.184364</td>\n",
              "      <td>0.033782</td>\n",
              "      <td>0.044661</td>\n",
              "      <td>0.012355</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041484</td>\n",
              "      <td>0.041990</td>\n",
              "      <td>0.019992</td>\n",
              "      <td>0.025515</td>\n",
              "      <td>0.029433</td>\n",
              "      <td>0.048106</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.054742</td>\n",
              "      <td>0.007430</td>\n",
              "      <td>0.024924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>0.049748</td>\n",
              "      <td>0.042083</td>\n",
              "      <td>0.013244</td>\n",
              "      <td>0.049748</td>\n",
              "      <td>0.086194</td>\n",
              "      <td>0.039736</td>\n",
              "      <td>0.055911</td>\n",
              "      <td>0.016861</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040080</td>\n",
              "      <td>0.060822</td>\n",
              "      <td>0.032024</td>\n",
              "      <td>0.039689</td>\n",
              "      <td>0.046228</td>\n",
              "      <td>0.062323</td>\n",
              "      <td>0.044901</td>\n",
              "      <td>0.058937</td>\n",
              "      <td>0.010875</td>\n",
              "      <td>0.026596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E</td>\n",
              "      <td>5</td>\n",
              "      <td>0.086915</td>\n",
              "      <td>0.046641</td>\n",
              "      <td>0.018770</td>\n",
              "      <td>0.079822</td>\n",
              "      <td>0.086915</td>\n",
              "      <td>0.050638</td>\n",
              "      <td>0.050466</td>\n",
              "      <td>0.022397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028962</td>\n",
              "      <td>0.062234</td>\n",
              "      <td>0.023879</td>\n",
              "      <td>0.030534</td>\n",
              "      <td>0.040489</td>\n",
              "      <td>0.065195</td>\n",
              "      <td>0.044938</td>\n",
              "      <td>0.068038</td>\n",
              "      <td>0.012156</td>\n",
              "      <td>0.038034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>L</td>\n",
              "      <td>6</td>\n",
              "      <td>0.060736</td>\n",
              "      <td>0.038191</td>\n",
              "      <td>0.009217</td>\n",
              "      <td>0.065189</td>\n",
              "      <td>0.152547</td>\n",
              "      <td>0.020950</td>\n",
              "      <td>0.049525</td>\n",
              "      <td>0.013955</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040042</td>\n",
              "      <td>0.096484</td>\n",
              "      <td>0.020712</td>\n",
              "      <td>0.035022</td>\n",
              "      <td>0.046888</td>\n",
              "      <td>0.049071</td>\n",
              "      <td>0.046247</td>\n",
              "      <td>0.048276</td>\n",
              "      <td>0.010486</td>\n",
              "      <td>0.022727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06ca4a4e-fb6c-4116-9d5a-d009a9039224')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-06ca4a4e-fb6c-4116-9d5a-d009a9039224 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-06ca4a4e-fb6c-4116-9d5a-d009a9039224');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bert old approach"
      ],
      "metadata": {
        "id": "VLYI3u1r0jvQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gDRQRXyn0R3y"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "from berteome import berteomeDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsKRHpCr0R3y",
        "outputId": "c8f08fb3-16b2-4146-e29f-3d624377e068"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# export\n",
        "tokenizer = BertTokenizer.from_pretrained(\"Rostlab/prot_bert\", do_lower_case=False )\n",
        "model = BertForMaskedLM.from_pretrained(\"Rostlab/prot_bert\")\n",
        "unmasker = pipeline('fill-mask', model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udR_0xEA0R3z"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def spacifySeq(seq):\n",
        "  return ' '.join(list(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CT8zI7Nw0R30"
      },
      "outputs": [],
      "source": [
        "assert spacifySeq(\"MENDEL\") == 'M E N D E L'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8_X3Naz0R31",
        "outputId": "411f933d-7753-4d9e-ff6d-e4d9d0da8c6c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'M E N D E L'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "' '.join(list(\"MENDEL\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO5qozgY0R32"
      },
      "outputs": [],
      "source": [
        "# export \n",
        "def maskifySeq(seq, pos, mask=\"[MASK]\"):\n",
        "  spacifiedSeq = spacifySeq(seq)\n",
        "  seqList = spacifiedSeq.split()\n",
        "  seqList[pos] = mask\n",
        "  return \" \".join(seqList)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5xXsI6o0R32",
        "outputId": "49b093f3-5347-436d-86f2-7f36397fa804"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'maskifySeq' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/x1/098shbqn0rs8vd5ybvyb0k9h0000gn/T/ipykernel_79310/236712703.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mmaskifySeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MENDEL\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'M E N [MASK] E L'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'maskifySeq' is not defined"
          ]
        }
      ],
      "source": [
        "assert maskifySeq(\"MENDEL\", 3) == 'M E N [MASK] E L'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa29ygHh0R33"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def allResidueCoordinates(seq,residue):\n",
        "  return [i for i, x in enumerate(seq) if x == residue]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YvHU8DT0R35"
      },
      "source": [
        "This should be renamed, to something along the lines of bertPredictionDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5olhAXW0R37"
      },
      "outputs": [],
      "source": [
        "# export\n",
        "def aaPosDict(aas):\n",
        "    aaDict = {}\n",
        "    for aaPos in range(len(aas)):\n",
        "        aa = aas[aaPos]\n",
        "        aaDict[aa] = aaPos\n",
        "    return aaDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSdYi1UP0R38",
        "outputId": "07dce813-9e8a-471b-d442-9409f528fa5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'A': 0,\n",
              " 'C': 1,\n",
              " 'D': 2,\n",
              " 'E': 3,\n",
              " 'F': 4,\n",
              " 'G': 5,\n",
              " 'H': 6,\n",
              " 'I': 7,\n",
              " 'K': 8,\n",
              " 'L': 9,\n",
              " 'M': 10,\n",
              " 'N': 11,\n",
              " 'P': 12,\n",
              " 'Q': 13,\n",
              " 'R': 14,\n",
              " 'S': 15,\n",
              " 'T': 16,\n",
              " 'V': 17,\n",
              " 'W': 18,\n",
              " 'Y': 19}"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aaPosDict(\"ACDEFGHIKLMNPQRSTVWY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lBRgWMd0R39"
      },
      "outputs": [],
      "source": [
        "# export \n",
        "def bertPredictionDF(seq, aas=\"ACDEFGHIKLMNPQRSTVWY\"):\n",
        "  aaDict = aaPosDict(aas)\n",
        "  bertPredDict = {}\n",
        "  # posPredictions = []\n",
        "  for aaPos in range(len(seq)):\n",
        "    aa = seq[aaPos]\n",
        "    maskPosSeq = maskifySeq(seq, aaPos)\n",
        "    predictions = unmasker(maskPosSeq, top_k=30)\n",
        "    predList = [0]*len(aas)\n",
        "    for prediction in predictions:\n",
        "      predAA = prediction[\"token_str\"]\n",
        "      if predAA in aaDict:\n",
        "        predList[aaDict[predAA]] = prediction[\"score\"]\n",
        "    bertPredDict[aaPos] = predList\n",
        "  bertPredDF = berteomeDF.modelPredDF(bertPredDict,seq, aas).predDf\n",
        "  return bertPredDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFAkPRnk0R3-",
        "outputId": "96fd75e9-67d2-4015-d99d-8f0e0b94eac5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wt</th>\n",
              "      <th>wtIndex</th>\n",
              "      <th>A</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>E</th>\n",
              "      <th>F</th>\n",
              "      <th>G</th>\n",
              "      <th>H</th>\n",
              "      <th>I</th>\n",
              "      <th>...</th>\n",
              "      <th>M</th>\n",
              "      <th>N</th>\n",
              "      <th>P</th>\n",
              "      <th>Q</th>\n",
              "      <th>R</th>\n",
              "      <th>S</th>\n",
              "      <th>T</th>\n",
              "      <th>V</th>\n",
              "      <th>W</th>\n",
              "      <th>Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>1</td>\n",
              "      <td>0.036685</td>\n",
              "      <td>0.011501</td>\n",
              "      <td>0.048229</td>\n",
              "      <td>0.118868</td>\n",
              "      <td>0.024064</td>\n",
              "      <td>0.039190</td>\n",
              "      <td>0.012617</td>\n",
              "      <td>0.066477</td>\n",
              "      <td>...</td>\n",
              "      <td>0.076580</td>\n",
              "      <td>0.072637</td>\n",
              "      <td>0.024714</td>\n",
              "      <td>0.038660</td>\n",
              "      <td>0.043091</td>\n",
              "      <td>0.070257</td>\n",
              "      <td>0.056526</td>\n",
              "      <td>0.049911</td>\n",
              "      <td>0.007779</td>\n",
              "      <td>0.021692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E</td>\n",
              "      <td>2</td>\n",
              "      <td>0.045712</td>\n",
              "      <td>0.015659</td>\n",
              "      <td>0.041913</td>\n",
              "      <td>0.074816</td>\n",
              "      <td>0.037146</td>\n",
              "      <td>0.044317</td>\n",
              "      <td>0.018260</td>\n",
              "      <td>0.073063</td>\n",
              "      <td>...</td>\n",
              "      <td>0.043572</td>\n",
              "      <td>0.062655</td>\n",
              "      <td>0.025272</td>\n",
              "      <td>0.036905</td>\n",
              "      <td>0.055532</td>\n",
              "      <td>0.064412</td>\n",
              "      <td>0.049945</td>\n",
              "      <td>0.056779</td>\n",
              "      <td>0.012689</td>\n",
              "      <td>0.029887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N</td>\n",
              "      <td>3</td>\n",
              "      <td>0.043558</td>\n",
              "      <td>0.009684</td>\n",
              "      <td>0.162566</td>\n",
              "      <td>0.184336</td>\n",
              "      <td>0.033777</td>\n",
              "      <td>0.044654</td>\n",
              "      <td>0.012353</td>\n",
              "      <td>0.052622</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041478</td>\n",
              "      <td>0.041984</td>\n",
              "      <td>0.019989</td>\n",
              "      <td>0.025511</td>\n",
              "      <td>0.029428</td>\n",
              "      <td>0.048098</td>\n",
              "      <td>0.030299</td>\n",
              "      <td>0.054734</td>\n",
              "      <td>0.007428</td>\n",
              "      <td>0.024920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>D</td>\n",
              "      <td>4</td>\n",
              "      <td>0.042079</td>\n",
              "      <td>0.013243</td>\n",
              "      <td>0.049744</td>\n",
              "      <td>0.086189</td>\n",
              "      <td>0.039733</td>\n",
              "      <td>0.055907</td>\n",
              "      <td>0.016860</td>\n",
              "      <td>0.073291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.040078</td>\n",
              "      <td>0.060817</td>\n",
              "      <td>0.032022</td>\n",
              "      <td>0.039686</td>\n",
              "      <td>0.046224</td>\n",
              "      <td>0.062319</td>\n",
              "      <td>0.044898</td>\n",
              "      <td>0.058933</td>\n",
              "      <td>0.010875</td>\n",
              "      <td>0.026594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E</td>\n",
              "      <td>5</td>\n",
              "      <td>0.046638</td>\n",
              "      <td>0.018769</td>\n",
              "      <td>0.079816</td>\n",
              "      <td>0.086908</td>\n",
              "      <td>0.050634</td>\n",
              "      <td>0.050462</td>\n",
              "      <td>0.022395</td>\n",
              "      <td>0.074495</td>\n",
              "      <td>...</td>\n",
              "      <td>0.028960</td>\n",
              "      <td>0.062229</td>\n",
              "      <td>0.023877</td>\n",
              "      <td>0.030532</td>\n",
              "      <td>0.040486</td>\n",
              "      <td>0.065190</td>\n",
              "      <td>0.044934</td>\n",
              "      <td>0.068032</td>\n",
              "      <td>0.012155</td>\n",
              "      <td>0.038031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>L</td>\n",
              "      <td>6</td>\n",
              "      <td>0.035695</td>\n",
              "      <td>0.008615</td>\n",
              "      <td>0.060928</td>\n",
              "      <td>0.142576</td>\n",
              "      <td>0.019581</td>\n",
              "      <td>0.046287</td>\n",
              "      <td>0.013043</td>\n",
              "      <td>0.060374</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037424</td>\n",
              "      <td>0.090177</td>\n",
              "      <td>0.019358</td>\n",
              "      <td>0.032733</td>\n",
              "      <td>0.043823</td>\n",
              "      <td>0.045863</td>\n",
              "      <td>0.043224</td>\n",
              "      <td>0.045121</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.021241</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "  wt  wtIndex         A         C         D         E         F         G  \\\n",
              "0  M        1  0.036685  0.011501  0.048229  0.118868  0.024064  0.039190   \n",
              "1  E        2  0.045712  0.015659  0.041913  0.074816  0.037146  0.044317   \n",
              "2  N        3  0.043558  0.009684  0.162566  0.184336  0.033777  0.044654   \n",
              "3  D        4  0.042079  0.013243  0.049744  0.086189  0.039733  0.055907   \n",
              "4  E        5  0.046638  0.018769  0.079816  0.086908  0.050634  0.050462   \n",
              "5  L        6  0.035695  0.008615  0.060928  0.142576  0.019581  0.046287   \n",
              "\n",
              "          H         I  ...         M         N         P         Q         R  \\\n",
              "0  0.012617  0.066477  ...  0.076580  0.072637  0.024714  0.038660  0.043091   \n",
              "1  0.018260  0.073063  ...  0.043572  0.062655  0.025272  0.036905  0.055532   \n",
              "2  0.012353  0.052622  ...  0.041478  0.041984  0.019989  0.025511  0.029428   \n",
              "3  0.016860  0.073291  ...  0.040078  0.060817  0.032022  0.039686  0.046224   \n",
              "4  0.022395  0.074495  ...  0.028960  0.062229  0.023877  0.030532  0.040486   \n",
              "5  0.013043  0.060374  ...  0.037424  0.090177  0.019358  0.032733  0.043823   \n",
              "\n",
              "          S         T         V         W         Y  \n",
              "0  0.070257  0.056526  0.049911  0.007779  0.021692  \n",
              "1  0.064412  0.049945  0.056779  0.012689  0.029887  \n",
              "2  0.048098  0.030299  0.054734  0.007428  0.024920  \n",
              "3  0.062319  0.044898  0.058933  0.010875  0.026594  \n",
              "4  0.065190  0.044934  0.068032  0.012155  0.038031  \n",
              "5  0.045863  0.043224  0.045121  0.009800  0.021241  \n",
              "\n",
              "[6 rows x 22 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bertPredictionDF(\"MENDEL\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-EU-BHX0R3_"
      },
      "source": [
        "I should probably think about this more, maybe I should go ahead and put the data into the dataframe format that I want from here. It probably doesn't make too much sense to make this structure (which has little utility) just to make the useful structure. Instead, I think I should go ahead and start iterating through predictions and add those predictions to a dict that will be easily converted to a dataframe.\n",
        "\n",
        "I think I would just need to know the intended index for the 20 amino acids, since the order of the predicitons is sorted by score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fJ_ORaR0R3_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.2 64-bit",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}